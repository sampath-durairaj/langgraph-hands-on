{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4676572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07e9480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f771321",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the current weather.\"\"\"\n",
    "    if location.lower() in [\"yorkshire\"]:\n",
    "        return \"It's cold and wet.\"\n",
    "    else:\n",
    "        return \"It's warm and sunny.\"\n",
    "tools = [get_weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35078a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b2752b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d4e09c490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [get_weather]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "graph.add_node(\"tool_node\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0022c9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d4e09c490>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prompt_node(state: State) -> State:\n",
    "    new_message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [new_message]}\n",
    "\n",
    "graph.add_node(\"prompt_node\", prompt_node)\n",
    "                                    \n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81f079bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d4e09c490>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conditional_edge(state: State) -> Literal['tool_node', '__end__']:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "    \n",
    "graph.add_conditional_edges(\n",
    "    'prompt_node',\n",
    "    conditional_edge\n",
    ")\n",
    "graph.add_edge(\"tool_node\", \"prompt_node\")\n",
    "graph.set_entry_point(\"prompt_node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dcc6fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Yorkshire is cold and wet.\n"
     ]
    }
   ],
   "source": [
    "APP = graph.compile()\n",
    "\n",
    "new_state = APP.invoke({\"messages\": [\"Whats the weather in yorkshire?\"]})\n",
    "\n",
    "print(new_state[\"messages\"][-1].content)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e66407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyparsing (from grandalf)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, grandalf\n",
      "\n",
      "   ---------------------------------------- 0/2 [pyparsing]\n",
      "   -------------------- ------------------- 1/2 [grandalf]\n",
      "   ---------------------------------------- 2/2 [grandalf]\n",
      "\n",
      "Successfully installed grandalf-0.8 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fef3ada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +-----------+             \n",
      "          | __start__ |             \n",
      "          +-----------+             \n",
      "                 *                  \n",
      "                 *                  \n",
      "                 *                  \n",
      "          +-------------+           \n",
      "          | prompt_node |           \n",
      "          +-------------+           \n",
      "          ...         ***           \n",
      "         .               *          \n",
      "       ..                 **        \n",
      "+---------+           +-----------+ \n",
      "| __end__ |           | tool_node | \n",
      "+---------+           +-----------+ \n"
     ]
    }
   ],
   "source": [
    "APP.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
